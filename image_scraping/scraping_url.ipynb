{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time,datetime\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 3\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_check(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"폴더 생성: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"폴더가 이미 존재함: {folder_path}\")\n",
    "    return folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더가 이미 존재함: C:\\Users\\royal\\OneDrive\\바탕 화면\\NLP_workbench\\utils\n",
      "폴더가 이미 존재함: C:\\Users\\royal\\OneDrive\\바탕 화면\\NLP_workbench\\logs\n",
      "C:\\Users\\royal\\OneDrive\\바탕 화면\\NLP_workbench\n",
      "C:\\Users\\royal\\OneDrive\\바탕 화면\\NLP_workbench\\utils\\chromedriver.exe\n",
      "C:\\Users\\royal\\OneDrive\\바탕 화면\\NLP_workbench\\category.txt\n"
     ]
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "util_path = path_check(os.path.join(curr_path,'utils'))\n",
    "log_path = path_check(os.path.join(curr_path,'logs'))\n",
    "driver_path = os.path.join(util_path,'chromedriver.exe')\n",
    "category_raw_path = os.path.join(curr_path,'category.txt')\n",
    "\n",
    "print(curr_path)\n",
    "print(driver_path)\n",
    "print(category_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(context,log_path = log_path):\n",
    "    with open (os.path.join(log_path,'log.txt'),'a') as f:\n",
    "        f.write(f'{datetime.datetime.today().strftime(\"%Y/%m/%d %H:%M:%S\")} : {context}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['renaissance']\n"
     ]
    }
   ],
   "source": [
    "with open(category_raw_path,'r') as f:\n",
    "    raw_lst = f.readlines()[0].split(',')\n",
    "    category_lst = [category.strip().lower() for category in raw_lst]\n",
    "print(category_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df(url_lst,category):\n",
    "    folder_path = os.path.join(curr_path,'urls')\n",
    "    url_dct = {'url':url_lst}\n",
    "    path_check(folder_path)\n",
    "    df = pd.DataFrame(url_dct)\n",
    "    df.to_csv(os.path.join(folder_path,category+'.csv'))\n",
    "    logging(f'Write {category}.csv at {folder_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(category,driver_path):\n",
    "    collected_url = []\n",
    "    cnt = 0\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get('https://artsandculture.google.com/category/art-movement?hl=en')\n",
    "    SCROLL_PAUSE_SEC = 1.5\n",
    "    actions = ActionChains(driver)\n",
    "    # 스크롤 높이 가져옴\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        # 끝까지 스크롤 다운\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # 1초 대기\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "        # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    time.sleep(5)\n",
    "    for i in range(1,125):\n",
    "        element_xpath = f'//*[@id=\"tab_pop\"]/div/ul/li[{i}]/a/span/span/span[1]'\n",
    "        element = WebDriverWait(driver, 120).until(EC.presence_of_element_located((By.XPATH, element_xpath)))\n",
    "        if element.text.strip().lower() == category:\n",
    "            # 상위 a 태그로 이동\n",
    "            parent_element = driver.find_element(By.XPATH, element_xpath.split('/span')[0])\n",
    "            # href 속성 가져오기\n",
    "            category_url = parent_element.get_attribute('href')\n",
    "            driver.get(category_url)\n",
    "            break\n",
    "    else : return False\n",
    "    time.sleep(random.randint(5, 10))\n",
    "    element = driver.find_element(By.CLASS_NAME, \"ldhC4e.PJLMUc\")\n",
    "    element.click()\n",
    "    time.sleep(5)\n",
    "    while True:\n",
    "    # 현재 페이지의 URL 얻기\n",
    "        initial_url = driver.current_url\n",
    "        logging(f'{category} | {initial_url}')\n",
    "        collected_url.append(initial_url)\n",
    "        # 다음 버튼 클릭\n",
    "        cnt+=1\n",
    "        if(cnt%100==0):\n",
    "            print(cnt)\n",
    "        else:\n",
    "            print(cnt, end = ' ')\n",
    "        actions.send_keys(Keys.ARROW_RIGHT).perform()\n",
    "        time.sleep(7)\n",
    "        changed_url = driver.current_url\n",
    "        if (cnt>=1300) or (changed_url == initial_url):            \n",
    "            print('No more pages.')\n",
    "            driver.quit()\n",
    "            write_df(collected_url,category)\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in category_lst:\n",
    "    res = scraping(category,driver_path)\n",
    "    print(f'{category} finished, result{res}')\n",
    "print('all_job_finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
